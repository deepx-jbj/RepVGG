[2023-10-16 14:57:43 RepVGG-A2] (main.py 466): INFO AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  PRESET: weak
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 32
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /mnt/datasets/ILSVRC2012
  IMG_SIZE: 320
  INTERPOLATION: bilinear
  NUM_WORKERS: 8
  PIN_MEMORY: true
  TEST_BATCH_SIZE: 32
  TEST_SIZE: 320
  ZIP_MODE: false
EVAL_MODE: false
LOCAL_RANK: 1
MODEL:
  ARCH: RepVGG-A2
  LABEL_SMOOTHING: 0.1
  NUM_CLASSES: 1000
  RESUME: ''
OUTPUT: train_results/RepVGG-A2/qmaster
PRINT_FREQ: 10
SAVE_FREQ: 20
SEED: 0
TAG: qmaster
TEST:
  CROP: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: true
  BASE_LR: 0.00025
  CLIP_GRAD: 0.0
  EMA_ALPHA: 0.0
  EMA_UPDATE_PERIOD: 8
  EPOCHS: 300
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MIN_LR: 0.0
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  SCALES_PATH: null
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 0
  WARMUP_LR: 0.0
  WEIGHT_DECAY: 0.0001

[2023-10-16 14:57:47 RepVGG-A2] (main.py 87): INFO Creating model:RepVGG-A2
[2023-10-16 14:57:48 RepVGG-A2] (main.py 97): INFO RepVGG(
  (stage0): RepVGGBlock(
    (nonlinearity): ReLU()
    (se): Identity()
    (dx_add): DxAdd()
    (rbr_reparam): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  )
  (stage1): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (stage2): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (2): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (3): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (stage3): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (2): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (3): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (4): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (5): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (6): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (7): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (8): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (9): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (10): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (11): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (12): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (13): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (stage4): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(384, 1408, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
  )
  (gap): AdaptiveAvgPool2d(output_size=1)
  (linear): Linear(in_features=1408, out_features=1000, bias=True)
  (identity): Identity()
  (dx_view): DxView()
)
[2023-10-16 14:57:53 RepVGG-A2] (main.py 150): INFO number of params: 25508798
[2023-10-16 14:57:53 RepVGG-A2] (main.py 193): INFO no checkpoint found in train_results/RepVGG-A2/qmaster, ignoring auto resume
[2023-10-16 14:57:53 RepVGG-A2] (main.py 199): INFO Start training
[2023-10-16 14:57:55 RepVGG-A2] (main.py 328): INFO Train: [0/300][0/10009]	eta 6:12:12 lr 0.000250	time 2.2312 (2.2312)	loss 4.8503 (4.8503)	grad_norm 404.1352 (404.1352)	mem 6833MB
[2023-10-16 14:57:58 RepVGG-A2] (main.py 328): INFO Train: [0/300][10/10009]	eta 1:12:03 lr 0.000250	time 0.2217 (0.4324)	loss 156.5445 (113.0300)	grad_norm 1784.4022 (2559.7547)	mem 6833MB
[2023-10-16 14:58:00 RepVGG-A2] (main.py 328): INFO Train: [0/300][20/10009]	eta 0:54:58 lr 0.000250	time 0.2202 (0.3302)	loss 91.7240 (116.1050)	grad_norm 849.7984 (1807.5428)	mem 6833MB
[2023-10-16 14:58:02 RepVGG-A2] (main.py 328): INFO Train: [0/300][30/10009]	eta 0:48:48 lr 0.000250	time 0.2161 (0.2935)	loss 68.9777 (105.8542)	grad_norm 329.6267 (1399.0014)	mem 6833MB
[2023-10-16 14:58:04 RepVGG-A2] (main.py 328): INFO Train: [0/300][40/10009]	eta 0:45:38 lr 0.000250	time 0.2140 (0.2747)	loss 71.5378 (92.4235)	grad_norm 144.8335 (1122.0016)	mem 6833MB
[2023-10-16 14:58:06 RepVGG-A2] (main.py 328): INFO Train: [0/300][50/10009]	eta 0:43:41 lr 0.000250	time 0.2147 (0.2632)	loss 47.4476 (83.6215)	grad_norm 308.0676 (938.7660)	mem 6833MB
[2023-10-16 14:58:10 RepVGG-A2] (main.py 328): INFO Train: [0/300][60/10009]	eta 0:46:31 lr 0.000250	time 0.8594 (0.2806)	loss 17.5427 (75.8753)	grad_norm 136.0468 (804.5399)	mem 6833MB
[2023-10-16 14:58:13 RepVGG-A2] (main.py 328): INFO Train: [0/300][70/10009]	eta 0:47:15 lr 0.000250	time 0.3358 (0.2853)	loss 17.5548 (70.1341)	grad_norm 67.7948 (702.3916)	mem 6833MB
[2023-10-16 14:58:17 RepVGG-A2] (main.py 328): INFO Train: [0/300][80/10009]	eta 0:48:28 lr 0.000250	time 0.3542 (0.2929)	loss 22.9300 (64.2599)	grad_norm 55.1716 (626.5741)	mem 6833MB
[2023-10-16 14:58:20 RepVGG-A2] (main.py 328): INFO Train: [0/300][90/10009]	eta 0:49:06 lr 0.000250	time 0.3594 (0.2971)	loss 17.8937 (60.1573)	grad_norm 60.3320 (564.2287)	mem 6833MB
[2023-10-16 14:58:23 RepVGG-A2] (main.py 328): INFO Train: [0/300][100/10009]	eta 0:49:44 lr 0.000250	time 0.3873 (0.3012)	loss 36.5043 (57.3600)	grad_norm 48.8305 (513.5333)	mem 6833MB
[2023-10-16 14:58:27 RepVGG-A2] (main.py 328): INFO Train: [0/300][110/10009]	eta 0:50:14 lr 0.000250	time 0.3089 (0.3045)	loss 32.5369 (54.1340)	grad_norm 48.4253 (471.6440)	mem 6833MB
[2023-10-16 14:58:30 RepVGG-A2] (main.py 328): INFO Train: [0/300][120/10009]	eta 0:50:41 lr 0.000250	time 0.3197 (0.3076)	loss 13.1931 (51.3277)	grad_norm 43.7141 (436.4250)	mem 6833MB
[2023-10-16 14:58:34 RepVGG-A2] (main.py 328): INFO Train: [0/300][130/10009]	eta 0:50:55 lr 0.000250	time 0.2964 (0.3092)	loss 21.7449 (48.8822)	grad_norm 41.1154 (406.4464)	mem 6833MB
[2023-10-16 14:58:37 RepVGG-A2] (main.py 328): INFO Train: [0/300][140/10009]	eta 0:51:09 lr 0.000250	time 0.3362 (0.3110)	loss 14.3084 (46.7368)	grad_norm 41.6684 (380.5503)	mem 6833MB
[2023-10-16 14:58:40 RepVGG-A2] (main.py 328): INFO Train: [0/300][150/10009]	eta 0:51:25 lr 0.000250	time 0.3785 (0.3129)	loss 38.9578 (44.6987)	grad_norm 39.8956 (357.9830)	mem 6833MB
[2023-10-16 14:58:44 RepVGG-A2] (main.py 328): INFO Train: [0/300][160/10009]	eta 0:51:35 lr 0.000250	time 0.3441 (0.3143)	loss 9.9016 (43.2896)	grad_norm 38.7894 (338.1847)	mem 6833MB
[2023-10-16 14:58:47 RepVGG-A2] (main.py 328): INFO Train: [0/300][170/10009]	eta 0:52:13 lr 0.000250	time 0.3544 (0.3185)	loss 15.8318 (41.6798)	grad_norm 38.1796 (320.6317)	mem 6833MB
[2023-10-16 14:58:51 RepVGG-A2] (main.py 328): INFO Train: [0/300][180/10009]	eta 0:52:20 lr 0.000250	time 0.3419 (0.3195)	loss 11.5429 (40.3227)	grad_norm 35.8458 (304.9500)	mem 6833MB
