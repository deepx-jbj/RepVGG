[2023-10-16 14:57:43 RepVGG-A2] (main.py 466): INFO AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  PRESET: weak
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 32
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /mnt/datasets/ILSVRC2012
  IMG_SIZE: 320
  INTERPOLATION: bilinear
  NUM_WORKERS: 8
  PIN_MEMORY: true
  TEST_BATCH_SIZE: 32
  TEST_SIZE: 320
  ZIP_MODE: false
EVAL_MODE: false
LOCAL_RANK: 3
MODEL:
  ARCH: RepVGG-A2
  LABEL_SMOOTHING: 0.1
  NUM_CLASSES: 1000
  RESUME: ''
OUTPUT: train_results/RepVGG-A2/qmaster
PRINT_FREQ: 10
SAVE_FREQ: 20
SEED: 0
TAG: qmaster
TEST:
  CROP: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: true
  BASE_LR: 0.00025
  CLIP_GRAD: 0.0
  EMA_ALPHA: 0.0
  EMA_UPDATE_PERIOD: 8
  EPOCHS: 300
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MIN_LR: 0.0
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  SCALES_PATH: null
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 0
  WARMUP_LR: 0.0
  WEIGHT_DECAY: 0.0001

[2023-10-16 14:57:47 RepVGG-A2] (main.py 87): INFO Creating model:RepVGG-A2
[2023-10-16 14:57:48 RepVGG-A2] (main.py 97): INFO RepVGG(
  (stage0): RepVGGBlock(
    (nonlinearity): ReLU()
    (se): Identity()
    (dx_add): DxAdd()
    (rbr_reparam): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  )
  (stage1): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (stage2): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (2): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (3): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (stage3): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (2): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (3): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (4): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (5): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (6): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (7): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (8): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (9): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (10): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (11): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (12): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (13): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (stage4): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(384, 1408, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
  )
  (gap): AdaptiveAvgPool2d(output_size=1)
  (linear): Linear(in_features=1408, out_features=1000, bias=True)
  (identity): Identity()
  (dx_view): DxView()
)
[2023-10-16 14:57:53 RepVGG-A2] (main.py 150): INFO number of params: 25508798
[2023-10-16 14:57:53 RepVGG-A2] (main.py 193): INFO no checkpoint found in train_results/RepVGG-A2/qmaster, ignoring auto resume
[2023-10-16 14:57:53 RepVGG-A2] (main.py 199): INFO Start training
[2023-10-16 14:57:55 RepVGG-A2] (main.py 328): INFO Train: [0/300][0/10009]	eta 6:05:34 lr 0.000250	time 2.1915 (2.1915)	loss 5.1049 (5.1049)	grad_norm 404.1352 (404.1352)	mem 6833MB
[2023-10-16 14:57:58 RepVGG-A2] (main.py 328): INFO Train: [0/300][10/10009]	eta 1:12:04 lr 0.000250	time 0.2219 (0.4325)	loss 157.8315 (109.0936)	grad_norm 1784.4022 (2559.7547)	mem 6833MB
[2023-10-16 14:58:00 RepVGG-A2] (main.py 328): INFO Train: [0/300][20/10009]	eta 0:54:58 lr 0.000250	time 0.2190 (0.3302)	loss 105.2523 (117.0294)	grad_norm 849.7984 (1807.5428)	mem 6833MB
[2023-10-16 14:58:02 RepVGG-A2] (main.py 328): INFO Train: [0/300][30/10009]	eta 0:48:48 lr 0.000250	time 0.2154 (0.2935)	loss 74.8627 (106.1186)	grad_norm 329.6267 (1399.0014)	mem 6833MB
[2023-10-16 14:58:04 RepVGG-A2] (main.py 328): INFO Train: [0/300][40/10009]	eta 0:45:38 lr 0.000250	time 0.2133 (0.2747)	loss 43.3480 (96.3495)	grad_norm 144.8335 (1122.0016)	mem 6833MB
[2023-10-16 14:58:06 RepVGG-A2] (main.py 328): INFO Train: [0/300][50/10009]	eta 0:43:41 lr 0.000250	time 0.2104 (0.2632)	loss 37.4002 (87.4393)	grad_norm 308.0676 (938.7660)	mem 6833MB
[2023-10-16 14:58:10 RepVGG-A2] (main.py 328): INFO Train: [0/300][60/10009]	eta 0:45:59 lr 0.000250	time 0.6604 (0.2773)	loss 21.9470 (79.5203)	grad_norm 136.0468 (804.5399)	mem 6833MB
[2023-10-16 14:58:13 RepVGG-A2] (main.py 328): INFO Train: [0/300][70/10009]	eta 0:47:16 lr 0.000250	time 0.3383 (0.2854)	loss 40.4697 (72.7329)	grad_norm 67.7948 (702.3916)	mem 6833MB
[2023-10-16 14:58:17 RepVGG-A2] (main.py 328): INFO Train: [0/300][80/10009]	eta 0:48:25 lr 0.000250	time 0.3415 (0.2927)	loss 40.2651 (68.5586)	grad_norm 55.1716 (626.5741)	mem 6833MB
[2023-10-16 14:58:20 RepVGG-A2] (main.py 328): INFO Train: [0/300][90/10009]	eta 0:49:04 lr 0.000250	time 0.3450 (0.2969)	loss 25.1242 (64.6959)	grad_norm 60.3320 (564.2287)	mem 6833MB
[2023-10-16 14:58:23 RepVGG-A2] (main.py 328): INFO Train: [0/300][100/10009]	eta 0:49:41 lr 0.000250	time 0.3774 (0.3009)	loss 40.7047 (60.4412)	grad_norm 48.8305 (513.5333)	mem 6833MB
[2023-10-16 14:58:27 RepVGG-A2] (main.py 328): INFO Train: [0/300][110/10009]	eta 0:50:14 lr 0.000250	time 0.3013 (0.3046)	loss 30.9577 (56.9465)	grad_norm 48.4253 (471.6440)	mem 6833MB
[2023-10-16 14:58:30 RepVGG-A2] (main.py 328): INFO Train: [0/300][120/10009]	eta 0:50:41 lr 0.000250	time 0.2933 (0.3076)	loss 8.5277 (53.7106)	grad_norm 43.7141 (436.4250)	mem 6833MB
[2023-10-16 14:58:34 RepVGG-A2] (main.py 328): INFO Train: [0/300][130/10009]	eta 0:50:58 lr 0.000250	time 0.3219 (0.3096)	loss 19.3947 (50.7971)	grad_norm 41.1154 (406.4464)	mem 6833MB
[2023-10-16 14:58:37 RepVGG-A2] (main.py 328): INFO Train: [0/300][140/10009]	eta 0:51:10 lr 0.000250	time 0.3474 (0.3111)	loss 11.2385 (48.2588)	grad_norm 41.6684 (380.5503)	mem 6833MB
[2023-10-16 14:58:40 RepVGG-A2] (main.py 328): INFO Train: [0/300][150/10009]	eta 0:51:23 lr 0.000250	time 0.3244 (0.3127)	loss 9.4124 (45.8655)	grad_norm 39.8956 (357.9830)	mem 6833MB
[2023-10-16 14:58:44 RepVGG-A2] (main.py 328): INFO Train: [0/300][160/10009]	eta 0:51:37 lr 0.000250	time 0.3539 (0.3145)	loss 18.5362 (43.9270)	grad_norm 38.7894 (338.1847)	mem 6833MB
[2023-10-16 14:58:47 RepVGG-A2] (main.py 328): INFO Train: [0/300][170/10009]	eta 0:52:13 lr 0.000250	time 0.3594 (0.3185)	loss 7.9678 (42.1995)	grad_norm 38.1796 (320.6317)	mem 6833MB
[2023-10-16 14:58:51 RepVGG-A2] (main.py 328): INFO Train: [0/300][180/10009]	eta 0:52:18 lr 0.000250	time 0.3194 (0.3193)	loss 9.3404 (40.4793)	grad_norm 35.8458 (304.9500)	mem 6833MB
