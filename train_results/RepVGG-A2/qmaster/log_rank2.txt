[2023-10-16 14:57:43 RepVGG-A2] (main.py 466): INFO AMP_OPT_LEVEL: O0
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  COLOR_JITTER: 0.4
  CUTMIX: 0.0
  CUTMIX_MINMAX: null
  MIXUP: 0.0
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  PRESET: weak
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
BASE:
- ''
DATA:
  BATCH_SIZE: 32
  CACHE_MODE: part
  DATASET: imagenet
  DATA_PATH: /mnt/datasets/ILSVRC2012
  IMG_SIZE: 320
  INTERPOLATION: bilinear
  NUM_WORKERS: 8
  PIN_MEMORY: true
  TEST_BATCH_SIZE: 32
  TEST_SIZE: 320
  ZIP_MODE: false
EVAL_MODE: false
LOCAL_RANK: 2
MODEL:
  ARCH: RepVGG-A2
  LABEL_SMOOTHING: 0.1
  NUM_CLASSES: 1000
  RESUME: ''
OUTPUT: train_results/RepVGG-A2/qmaster
PRINT_FREQ: 10
SAVE_FREQ: 20
SEED: 0
TAG: qmaster
TEST:
  CROP: false
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: true
  BASE_LR: 0.00025
  CLIP_GRAD: 0.0
  EMA_ALPHA: 0.0
  EMA_UPDATE_PERIOD: 8
  EPOCHS: 300
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MIN_LR: 0.0
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: sgd
  SCALES_PATH: null
  START_EPOCH: 0
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 0
  WARMUP_LR: 0.0
  WEIGHT_DECAY: 0.0001

[2023-10-16 14:57:47 RepVGG-A2] (main.py 87): INFO Creating model:RepVGG-A2
[2023-10-16 14:57:48 RepVGG-A2] (main.py 97): INFO RepVGG(
  (stage0): RepVGGBlock(
    (nonlinearity): ReLU()
    (se): Identity()
    (dx_add): DxAdd()
    (rbr_reparam): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  )
  (stage1): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (stage2): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (2): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (3): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (stage3): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (1): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (2): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (3): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (4): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (5): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (6): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (7): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (8): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (9): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (10): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (11): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (12): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (13): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (stage4): ModuleList(
    (0): RepVGGBlock(
      (nonlinearity): ReLU()
      (se): Identity()
      (dx_add): DxAdd()
      (rbr_reparam): Conv2d(384, 1408, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
  )
  (gap): AdaptiveAvgPool2d(output_size=1)
  (linear): Linear(in_features=1408, out_features=1000, bias=True)
  (identity): Identity()
  (dx_view): DxView()
)
[2023-10-16 14:57:53 RepVGG-A2] (main.py 150): INFO number of params: 25508798
[2023-10-16 14:57:53 RepVGG-A2] (main.py 193): INFO no checkpoint found in train_results/RepVGG-A2/qmaster, ignoring auto resume
[2023-10-16 14:57:53 RepVGG-A2] (main.py 199): INFO Start training
[2023-10-16 14:57:55 RepVGG-A2] (main.py 328): INFO Train: [0/300][0/10009]	eta 6:27:28 lr 0.000250	time 2.3227 (2.3227)	loss 3.7626 (3.7626)	grad_norm 404.1352 (404.1352)	mem 6833MB
[2023-10-16 14:57:58 RepVGG-A2] (main.py 328): INFO Train: [0/300][10/10009]	eta 1:12:00 lr 0.000250	time 0.2187 (0.4321)	loss 146.2961 (110.4674)	grad_norm 1784.4022 (2559.7547)	mem 6833MB
[2023-10-16 14:58:00 RepVGG-A2] (main.py 328): INFO Train: [0/300][20/10009]	eta 0:54:59 lr 0.000250	time 0.2220 (0.3303)	loss 113.6923 (113.5981)	grad_norm 849.7984 (1807.5428)	mem 6833MB
[2023-10-16 14:58:02 RepVGG-A2] (main.py 328): INFO Train: [0/300][30/10009]	eta 0:48:48 lr 0.000250	time 0.2151 (0.2935)	loss 71.7764 (102.0566)	grad_norm 329.6267 (1399.0014)	mem 6833MB
[2023-10-16 14:58:04 RepVGG-A2] (main.py 328): INFO Train: [0/300][40/10009]	eta 0:45:38 lr 0.000250	time 0.2158 (0.2747)	loss 38.6830 (93.9766)	grad_norm 144.8335 (1122.0016)	mem 6833MB
[2023-10-16 14:58:06 RepVGG-A2] (main.py 328): INFO Train: [0/300][50/10009]	eta 0:43:41 lr 0.000250	time 0.2154 (0.2632)	loss 28.8721 (85.5505)	grad_norm 308.0676 (938.7660)	mem 6833MB
[2023-10-16 14:58:10 RepVGG-A2] (main.py 328): INFO Train: [0/300][60/10009]	eta 0:46:06 lr 0.000250	time 0.7060 (0.2780)	loss 57.3850 (78.4130)	grad_norm 136.0468 (804.5399)	mem 6833MB
[2023-10-16 14:58:13 RepVGG-A2] (main.py 328): INFO Train: [0/300][70/10009]	eta 0:47:15 lr 0.000250	time 0.3324 (0.2853)	loss 20.6855 (73.4181)	grad_norm 67.7948 (702.3916)	mem 6833MB
[2023-10-16 14:58:17 RepVGG-A2] (main.py 328): INFO Train: [0/300][80/10009]	eta 0:48:26 lr 0.000250	time 0.3078 (0.2927)	loss 29.1339 (69.1364)	grad_norm 55.1716 (626.5741)	mem 6833MB
[2023-10-16 14:58:20 RepVGG-A2] (main.py 328): INFO Train: [0/300][90/10009]	eta 0:49:06 lr 0.000250	time 0.3436 (0.2970)	loss 17.6055 (64.4490)	grad_norm 60.3320 (564.2287)	mem 6833MB
[2023-10-16 14:58:23 RepVGG-A2] (main.py 328): INFO Train: [0/300][100/10009]	eta 0:49:39 lr 0.000250	time 0.3564 (0.3007)	loss 21.7443 (60.0107)	grad_norm 48.8305 (513.5333)	mem 6833MB
[2023-10-16 14:58:27 RepVGG-A2] (main.py 328): INFO Train: [0/300][110/10009]	eta 0:50:14 lr 0.000250	time 0.3569 (0.3046)	loss 23.8510 (56.6905)	grad_norm 48.4253 (471.6440)	mem 6833MB
[2023-10-16 14:58:30 RepVGG-A2] (main.py 328): INFO Train: [0/300][120/10009]	eta 0:50:41 lr 0.000250	time 0.2906 (0.3076)	loss 20.0782 (53.4221)	grad_norm 43.7141 (436.4250)	mem 6833MB
[2023-10-16 14:58:34 RepVGG-A2] (main.py 328): INFO Train: [0/300][130/10009]	eta 0:50:57 lr 0.000250	time 0.3260 (0.3095)	loss 8.6493 (50.5490)	grad_norm 41.1154 (406.4464)	mem 6833MB
[2023-10-16 14:58:37 RepVGG-A2] (main.py 328): INFO Train: [0/300][140/10009]	eta 0:51:09 lr 0.000250	time 0.3342 (0.3111)	loss 14.6009 (48.3956)	grad_norm 41.6684 (380.5503)	mem 6833MB
[2023-10-16 14:58:40 RepVGG-A2] (main.py 328): INFO Train: [0/300][150/10009]	eta 0:51:24 lr 0.000250	time 0.3599 (0.3128)	loss 17.5938 (46.0065)	grad_norm 39.8956 (357.9830)	mem 6833MB
[2023-10-16 14:58:44 RepVGG-A2] (main.py 328): INFO Train: [0/300][160/10009]	eta 0:51:35 lr 0.000250	time 0.3504 (0.3143)	loss 31.6187 (44.4330)	grad_norm 38.7894 (338.1847)	mem 6833MB
[2023-10-16 14:58:47 RepVGG-A2] (main.py 328): INFO Train: [0/300][170/10009]	eta 0:52:13 lr 0.000250	time 0.3555 (0.3185)	loss 28.2291 (42.6931)	grad_norm 38.1796 (320.6317)	mem 6833MB
[2023-10-16 14:58:51 RepVGG-A2] (main.py 328): INFO Train: [0/300][180/10009]	eta 0:52:18 lr 0.000250	time 0.3042 (0.3193)	loss 18.6892 (41.1364)	grad_norm 35.8458 (304.9500)	mem 6833MB
